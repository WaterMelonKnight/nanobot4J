## ğŸ¯ å¿«é€Ÿå¼€å§‹æŒ‡å—

### 1. é…ç½®ç¯å¢ƒå˜é‡

```bash
# DeepSeek API Key
export DEEPSEEK_API_KEY="sk-your-deepseek-api-key"

# Kimi (Moonshot) API Key
export KIMI_API_KEY="sk-your-kimi-api-key"

# å¯é€‰ï¼šOpenAI API Key
export OPENAI_API_KEY="sk-your-openai-api-key"
```

### 2. ä¿®æ”¹é…ç½®æ–‡ä»¶

ç¼–è¾‘ `src/main/resources/application.yml`ï¼š

```yaml
nanobot:
  llm:
    # è®¾ç½®é»˜è®¤æ¨¡å‹
    default-model: ollama  # å¯é€‰: ollama, deepseek, kimi, openai

    models:
      # å¯ç”¨/ç¦ç”¨ç‰¹å®šæ¨¡å‹
      deepseek:
        enabled: true
      kimi:
        enabled: true
      ollama:
        enabled: true
```

### 3. ä½¿ç”¨ç¤ºä¾‹

#### æ–¹å¼ 1: ä½¿ç”¨é»˜è®¤æ¨¡å‹

```java
@Service
public class MyService {
    @Autowired
    private LLMService llmService;

    public String chat(String userInput) {
        List<Message> messages = List.of(
            new Message.UserMessage(userInput)
        );

        Message.AssistantMessage response = llmService.chat(messages);
        return response.content();
    }
}
```

#### æ–¹å¼ 2: ä½¿ç”¨ @UseModel æ³¨è§£ï¼ˆæ¨èï¼‰

```java
@Service
public class CodeGenerationService {
    @Autowired
    private LLMService llmService;

    @UseModel("deepseek")
    public String generateJavaCode(String requirement) {
        // DeepSeek æ“…é•¿ä»£ç ç”Ÿæˆ
        List<Message> messages = List.of(
            new Message.SystemMessage("You are a Java expert"),
            new Message.UserMessage(requirement)
        );

        return llmService.chat(messages).content();
    }

    @UseModel("kimi")
    public String analyzeLongDocument(String document) {
        // Kimi æ”¯æŒé•¿æ–‡æœ¬ï¼ˆ8k tokensï¼‰
        List<Message> messages = List.of(
            new Message.UserMessage("Analyze this: " + document)
        );

        return llmService.chat(messages).content();
    }

    @UseModel("ollama")
    public String quickResponse(String query) {
        // Ollama æœ¬åœ°æ¨¡å‹ï¼Œå“åº”å¿«ï¼Œæ— éœ€ API Key
        List<Message> messages = List.of(
            new Message.UserMessage(query)
        );

        return llmService.chat(messages).content();
    }
}
```

#### æ–¹å¼ 3: åŠ¨æ€é€‰æ‹©æ¨¡å‹

```java
@Service
public class DynamicModelService {
    @Autowired
    private LLMService llmService;

    public String chatWithModel(String modelName, String userInput) {
        List<Message> messages = List.of(
            new Message.UserMessage(userInput)
        );

        // è¿è¡Œæ—¶åŠ¨æ€é€‰æ‹©æ¨¡å‹
        Message.AssistantMessage response =
            llmService.chatWithModel(modelName, messages);

        return response.content();
    }

    public void listAvailableModels() {
        Set<String> models = llmService.getAvailableModels();
        System.out.println("Available models: " + models);
        // è¾“å‡º: Available models: [ollama, deepseek, kimi]
    }
}
```

### 4. å·¥å…·è°ƒç”¨ï¼ˆFunction Callingï¼‰

```java
@Service
public class ToolCallingService {
    @Autowired
    private LLMService llmService;

    @Autowired
    private ToolRegistry toolRegistry;

    @UseModel("deepseek")  // DeepSeek æ”¯æŒ Function Calling
    public String chatWithTools(String userInput) {
        List<Message> messages = List.of(
            new Message.UserMessage(userInput)
        );

        // è·å–æ‰€æœ‰å¯ç”¨å·¥å…·
        List<Tool> tools = toolRegistry.getAllTools();

        // è°ƒç”¨ LLMï¼ˆæ”¯æŒå·¥å…·è°ƒç”¨ï¼‰
        Message.AssistantMessage response =
            llmService.chatWithTools(messages, tools);

        return response.content();
    }
}
```

### 5. ç›‘æ§å’Œç»Ÿè®¡

```java
@RestController
@RequestMapping("/api/llm")
public class LLMMonitorController {

    @Autowired
    private MultiModelLLMService llmService;

    @GetMapping("/stats")
    public Map<String, Object> getStats() {
        Map<String, Object> result = new HashMap<>();

        llmService.getStats().forEach((model, stats) -> {
            Map<String, Object> modelStats = new HashMap<>();
            modelStats.put("successCount", stats.getSuccessCount());
            modelStats.put("failureCount", stats.getFailureCount());
            modelStats.put("averageDurationMs", stats.getAverageDurationMs());
            modelStats.put("successRate", stats.getSuccessRate());

            result.put(model, modelStats);
        });

        return result;
    }
}
```

è¾“å‡ºç¤ºä¾‹ï¼š
```json
{
  "ollama": {
    "successCount": 150,
    "failureCount": 5,
    "averageDurationMs": 1200.5,
    "successRate": 0.9677
  },
  "deepseek": {
    "successCount": 80,
    "failureCount": 2,
    "averageDurationMs": 2500.3,
    "successRate": 0.9756
  },
  "kimi": {
    "successCount": 45,
    "failureCount": 1,
    "averageDurationMs": 3000.8,
    "successRate": 0.9783
  }
}
```

### 6. é™çº§ç­–ç•¥æµ‹è¯•

```java
@SpringBootTest
public class FallbackTest {

    @Autowired
    private LLMService llmService;

    @Test
    public void testFallback() {
        // é…ç½®é™çº§é¡ºåº: ollama -> deepseek -> kimi

        List<Message> messages = List.of(
            new Message.UserMessage("Hello!")
        );

        // å¦‚æœ Ollama ä¸å¯ç”¨ï¼Œä¼šè‡ªåŠ¨é™çº§åˆ° DeepSeek
        Message.AssistantMessage response = llmService.chat(messages);

        assertNotNull(response);
        assertNotNull(response.content());
    }
}
```

### 7. è¿è¡Œç¤ºä¾‹ç¨‹åº

```bash
# ç¼–è¯‘é¡¹ç›®
mvn clean package

# è¿è¡Œåº”ç”¨
mvn spring-boot:run

# æˆ–è€…ç›´æ¥è¿è¡Œ JAR
java -jar target/nanobot4j-1.0.0.jar
```

åº”ç”¨å¯åŠ¨åï¼Œä¼šè‡ªåŠ¨è¿è¡Œ `MultiModelExample`ï¼Œå±•ç¤ºæ‰€æœ‰ä½¿ç”¨æ–¹å¼ã€‚

### 8. å¸¸è§é—®é¢˜

#### Q1: å¦‚ä½•ç¦ç”¨æŸä¸ªæ¨¡å‹ï¼Ÿ
A: åœ¨ `application.yml` ä¸­è®¾ç½® `enabled: false`ï¼š
```yaml
models:
  deepseek:
    enabled: false  # ç¦ç”¨ DeepSeek
```

#### Q2: å¦‚ä½•è°ƒæ•´è¶…æ—¶æ—¶é—´ï¼Ÿ
A: ä¿®æ”¹æ¨¡å‹çš„ `timeout-ms` é…ç½®ï¼š
```yaml
models:
  ollama:
    timeout-ms: 60000  # 60 ç§’
```

#### Q3: å¦‚ä½•å…³é—­é™çº§ç­–ç•¥ï¼Ÿ
A: è®¾ç½® `fallback.enabled: false`ï¼š
```yaml
fallback:
  enabled: false
```

#### Q4: @UseModel æ³¨è§£ä¸ç”Ÿæ•ˆï¼Ÿ
A: ç¡®ä¿ï¼š
1. æ–¹æ³•æ˜¯ `public` çš„
2. ç±»è¢« Spring ç®¡ç†ï¼ˆæœ‰ `@Service`ã€`@Component` ç­‰æ³¨è§£ï¼‰
3. é€šè¿‡ Spring æ³¨å…¥è°ƒç”¨ï¼Œè€Œä¸æ˜¯ç›´æ¥ `new` å¯¹è±¡

#### Q5: å¦‚ä½•æ·»åŠ æ–°çš„æ¨¡å‹æä¾›å•†ï¼Ÿ
A: åœ¨ `application.yml` ä¸­æ·»åŠ é…ç½®ï¼š
```yaml
models:
  my-custom-model:
    enabled: true
    provider: openai-compatible  # å¦‚æœå…¼å®¹ OpenAI API
    base-url: https://api.example.com/v1
    api-key: ${MY_API_KEY}
    model: custom-model-name
```

### 9. æ€§èƒ½ä¼˜åŒ–å»ºè®®

1. **æœ¬åœ°æ¨¡å‹ä¼˜å…ˆ**ï¼šå°† Ollama è®¾ä¸ºé»˜è®¤æ¨¡å‹ï¼Œå‡å°‘ API è°ƒç”¨æˆæœ¬
2. **åˆç†è®¾ç½®è¶…æ—¶**ï¼šæ ¹æ®æ¨¡å‹ç‰¹æ€§è°ƒæ•´è¶…æ—¶æ—¶é—´
3. **å¯ç”¨é™çº§ç­–ç•¥**ï¼šç¡®ä¿é«˜å¯ç”¨æ€§
4. **ç›‘æ§ç»Ÿè®¡ä¿¡æ¯**ï¼šå®šæœŸæŸ¥çœ‹å„æ¨¡å‹çš„æˆåŠŸç‡å’Œå“åº”æ—¶é—´

### 10. ç”Ÿäº§ç¯å¢ƒéƒ¨ç½²

```yaml
# ç”Ÿäº§ç¯å¢ƒé…ç½®ç¤ºä¾‹
nanobot:
  llm:
    default-model: deepseek  # ç”Ÿäº§ç¯å¢ƒä½¿ç”¨äº‘ç«¯æ¨¡å‹

    models:
      deepseek:
        enabled: true
        timeout-ms: 30000

      kimi:
        enabled: true
        timeout-ms: 30000

      ollama:
        enabled: false  # ç”Ÿäº§ç¯å¢ƒå¯èƒ½æ²¡æœ‰æœ¬åœ°æ¨¡å‹

    fallback:
      enabled: true
      order: [deepseek, kimi]  # äº‘ç«¯æ¨¡å‹äº’ä¸ºå¤‡ä»½

# æ—¥å¿—çº§åˆ«
logging:
  level:
    com.nanobot.llm: INFO  # ç”Ÿäº§ç¯å¢ƒé™ä½æ—¥å¿—çº§åˆ«
```

---

## ğŸ‰ å®Œæˆï¼

ä½ ç°åœ¨æ‹¥æœ‰ä¸€ä¸ªåŠŸèƒ½å®Œæ•´çš„å¤šæ¨¡å‹ LLM æ¶æ„ã€‚å¼€å§‹ä½¿ç”¨å§ï¼

å¦‚æœ‰é—®é¢˜ï¼Œè¯·æŸ¥çœ‹ï¼š
- [MULTI_MODEL_GUIDE.md](MULTI_MODEL_GUIDE.md) - å®Œæ•´æ¶æ„æ–‡æ¡£
- [ARCHITECTURE.md](ARCHITECTURE.md) - ç³»ç»Ÿæ¶æ„è¯´æ˜
- [MultiModelExample.java](src/main/java/com/nanobot/example/MultiModelExample.java) - ç¤ºä¾‹ä»£ç 
