package com.nanobot.llm.mock;

import com.nanobot.domain.Message;
import com.nanobot.llm.LLMClient;
import com.nanobot.tool.Tool;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;
import org.springframework.stereotype.Component;

import java.time.Instant;
import java.util.List;

/**
 * Mock LLM Client - ç”¨äºæ¼”ç¤ºå’Œæµ‹è¯•
 *
 * è¿™æ˜¯ä¸€ä¸ªç®€å•çš„æ¨¡æ‹Ÿå®ç°ï¼Œè¿”å›é¢„å®šä¹‰çš„å“åº”ã€‚
 * åœ¨ç”Ÿäº§ç¯å¢ƒä¸­ï¼Œåº”è¯¥ä½¿ç”¨çœŸå®çš„ LLM å®¢æˆ·ç«¯ï¼ˆå¦‚ OpenAIã€Ollama ç­‰ï¼‰ã€‚
 */
@Component
public class MockLLMClient implements LLMClient {

    private static final Logger log = LoggerFactory.getLogger(MockLLMClient.class);

    @Override
    public Message.AssistantMessage chat(List<Message> messages) {
        return chatWithTools(messages, List.of());
    }

    @Override
    public String getModelName() {
        return "mock-llm-client";
    }

    @Override
    public Message.AssistantMessage chatWithTools(List<Message> messages, List<Tool> tools) {
        log.info("MockLLMClient received {} messages", messages.size());

        // è·å–æœ€åä¸€æ¡ç”¨æˆ·æ¶ˆæ¯
        String userMessage = messages.stream()
                .filter(m -> m instanceof Message.UserMessage)
                .map(m -> ((Message.UserMessage) m).content())
                .reduce((first, second) -> second)
                .orElse("");

        // ç”Ÿæˆç®€å•çš„å“åº”
        String response = generateMockResponse(userMessage);

        return new Message.AssistantMessage(
                "mock-" + System.currentTimeMillis(),
                response,
                List.of(),
                Instant.now()
        );
    }

    private String generateMockResponse(String userMessage) {
        String lowerMessage = userMessage.toLowerCase();

        if (lowerMessage.contains("ä½ å¥½") || lowerMessage.contains("hello") || lowerMessage.contains("hi")) {
            return "ä½ å¥½ï¼æˆ‘æ˜¯ Nanobot4J çš„ Mock LLM å®¢æˆ·ç«¯ã€‚ç›®å‰ä½¿ç”¨çš„æ˜¯æ¨¡æ‹Ÿå“åº”ã€‚\n\n" +
                   "è¦ä½¿ç”¨çœŸå®çš„ LLM æ¨¡å‹ï¼Œè¯·é…ç½®ä»¥ä¸‹é€‰é¡¹ä¹‹ä¸€ï¼š\n" +
                   "1. OpenAI API\n" +
                   "2. Ollama æœ¬åœ°æ¨¡å‹\n" +
                   "3. DeepSeek API\n" +
                   "4. å…¶ä»–å…¼å®¹ OpenAI çš„ API";
        }

        if (lowerMessage.contains("å¸®åŠ©") || lowerMessage.contains("help")) {
            return "Nanobot4J åŠŸèƒ½è¯´æ˜ï¼š\n\n" +
                   "âœ“ å¤šè½®å¯¹è¯ç®¡ç†\n" +
                   "âœ“ ä¼šè¯æŒä¹…åŒ–\n" +
                   "âœ“ Agent é…ç½®ç®¡ç†\n" +
                   "âœ“ å·¥å…·è°ƒç”¨æ”¯æŒ\n" +
                   "âœ“ RESTful API\n" +
                   "âœ“ Swagger æ–‡æ¡£\n\n" +
                   "å½“å‰ä½¿ç”¨ Mock æ¨¡å¼ï¼Œè¯·é…ç½®çœŸå®çš„ LLM å®¢æˆ·ç«¯ä»¥è·å¾—å®Œæ•´åŠŸèƒ½ã€‚";
        }

        if (lowerMessage.contains("è®¡ç®—") || lowerMessage.contains("æ•°å­¦")) {
            return "æˆ‘æ˜¯ä¸€ä¸ª Mock å®¢æˆ·ç«¯ï¼Œæ— æ³•æ‰§è¡ŒçœŸå®çš„è®¡ç®—ã€‚\n" +
                   "é…ç½®çœŸå®çš„ LLM å®¢æˆ·ç«¯åï¼Œæˆ‘å¯ä»¥å¸®ä½ è¿›è¡Œæ•°å­¦è®¡ç®—å’Œå…¶ä»–ä»»åŠ¡ã€‚";
        }

        // é»˜è®¤å“åº”
        return String.format("æ”¶åˆ°ä½ çš„æ¶ˆæ¯ï¼šã€Œ%sã€\n\n" +
                           "è¿™æ˜¯æ¥è‡ª Mock LLM å®¢æˆ·ç«¯çš„å“åº”ã€‚å½“å‰ç³»ç»Ÿè¿è¡Œæ­£å¸¸ï¼Œä½†ä½¿ç”¨çš„æ˜¯æ¨¡æ‹Ÿæ¨¡å¼ã€‚\n\n" +
                           "ğŸ’¡ æç¤ºï¼šè¦è·å¾—çœŸå®çš„ AI å¯¹è¯èƒ½åŠ›ï¼Œè¯·åœ¨ application.yml ä¸­é…ç½® LLM æœåŠ¡ã€‚",
                           userMessage.length() > 50 ? userMessage.substring(0, 50) + "..." : userMessage);
    }
}
